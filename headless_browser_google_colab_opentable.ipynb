{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "headless_browser_google_colab_opentable.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCM/2rWsP65j9NBQhJnjut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harslan/Notebooks/blob/master/headless_browser_google_colab_opentable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mncjVW4FuQ_e",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Web Scraping: \n",
        "\n",
        "## Learning Objectives\n",
        "- Learn how to locate HTML elements on a webpage.\n",
        "- Convert HTML data from a webpage into searchable object using Beautiful soup.\n",
        "- Discuss limitations associated with simple requests library.\n",
        "- Introduce Selenium as a solution, and implement a headless browser scraper using Selenium."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeNOgGmfu2Jq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## What is Selenium?\n",
        "\n",
        "Selenium is a headless browser. It allows us to render JavaScript content just as a human-navigated browser would.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8CcFAjAu9q9",
        "colab_type": "text"
      },
      "source": [
        "## Running in Google Colabs\n",
        "\n",
        "If you are running your Python code in Google Colabs, we are going to run the following installations to install Selenium and Chromium Chromedriver:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvFS-R9Gv2t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "chmod 777 /tmp\n",
        "mkdir data\n",
        "apt-get update --allow-unauthenticated \n",
        "apt-get update -y --fix-missing \n",
        "pip install selenium\n",
        "apt-get install chromium-chromedriver -y --fix-missing\n",
        "pip install joblib\n",
        "apt-get update --fix-missing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi4tOEjF6jqd",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"intro\"></a>\n",
        "## Introduction\n",
        "\n",
        "In this lesson, we'll build a web scraper using requests and BeautifulSoup librarires in Python. We will also explore how to use a headless browser called Selenium.\n",
        "\n",
        "We'll begin by scraping OpenTable's Boston listings. We're interested in knowing the restaurant's **name and location**. OpenTable provides all of this information on the following page: http://www.opentable.com/boston-restaurant-listings \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYTuAIJo7wPp",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"building-scraper\"></a>\n",
        "## Building a web scraper\n",
        "\n",
        "Let's build a web scraper for scraping data from OpenTable website using requests and Beautiful Soup libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRGxd4aL75dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import our packages\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# set the url we want to visit\n",
        "url = \"http://www.opentable.com/boston-restaurant-listings\"\n",
        "\n",
        "# visit the webpage at the url and retrieve its corresponding html content\n",
        "html = requests.get(url)\n",
        "\n",
        "# .text method returns the request content in Unicode\n",
        "print(html.text)\n",
        "\n",
        "# convert this content into a BeautifulSoup object\n",
        "soup = BeautifulSoup(html.text, 'html.parser')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyz2nEL4BXzA",
        "colab_type": "text"
      },
      "source": [
        "When you look into the content of html.text above, you will realize that its contents do not reflect the list of restaurants in Boston."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju0a8lB-aRi0",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"selenium\"></a>\n",
        "## Introducing Selenium\n",
        "\n",
        "Let's build a web scraper for scraping data from OpenTable website using Selenium headless browser and Beautiful Soup library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Lvb5YYaXAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Headless Browser with BeautifulSoup\n",
        "import selenium\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.binary_location = '/usr/bin/chromium-browser'\n",
        "\n",
        "driver = webdriver.Chrome(executable_path='/usr/bin/chromedriver', options = options)\n",
        "driver.get(\"http://www.opentable.com/boston-restaurant-listings\")\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NgDHkx6gUcF",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"retrieving-data\"></a>\n",
        "### Retrieving data from the HTML page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHuzJ0Vlgd-a",
        "colab_type": "text"
      },
      "source": [
        "Before we start scraping the restaurant names, let's find each restaurant name listed on the page we've loaded. To achieve this, we nee to find where in the **HTML** the restaurant element is stored. In order to find the HTML that renders the restaurant location, we can use Google Chrome's Inspect tool:\n",
        "\n",
        "> http://www.opentable.com/boston-restaurant-listings\n",
        "> 1. Visit the URL above. \n",
        "\n",
        "> 2. Right-click on an element you are interested in, then choose Inspect (in Chrome). \n",
        "\n",
        "> 3. This will open the Developer Tools and show the HTML used to render the selected page element. \n",
        "\n",
        "> Throughout this lesson, we will use this method to find tags associated with elements of the page we want to scrape.\n",
        "\n",
        "The general idea is: restaurant namaes are structured in the same HTML element on the webpage. If we can identify this structure, we can use it to extract the corresponding data from these HTML elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz1OS2CPgeaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the restaurant names\n",
        "soup.find_all(name='span', attrs={'class':'rest-row-name-text'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL2N4SQaiHLu",
        "colab_type": "text"
      },
      "source": [
        "We note that the above returned object from find_all method is a `list`. We observe the outer square brackets and commas separating each tag. We also note that the elements of the list are `Tag` objects, not strings.  The Beautiful Soup library uses a `Tag` object as a visual representation of a tag and its text contents. However, being an object, it has many methods that we can call on it. For example, next we will use the `text()` method to return the tag's contents as a Python string.\n",
        "\n",
        "<a id=\"retrieving-names\"></a>\n",
        "#### Retrieving the restaurant names\n",
        "\n",
        "After finding a list of tags containing the restaurant names, we can also loop through them and print the restaurant names. We utilize `text()` method to get the clean text contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbvGG4I-jIyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for each element you find, print out the restaurant name\n",
        "for entry in soup.find_all(name='span', attrs={'class':'rest-row-name-text'}):\n",
        "    print(entry.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqlXZgdCkDoD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<a id=\"retrieving-locations\"></a>\n",
        "#### Retrieving the restaurant locations\n",
        "\n",
        "Let us repeat our above process to find restaurant locations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5V8XHhxkEQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now print out the location of each restaurant\n",
        "for entry in soup.find_all('span', {'class':'rest-row-meta--location rest-row-meta-text sfx1388addContent'}):\n",
        "    print(entry.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEty_cJKlScn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<a id=\"retrieving-review-numbers\"></a>\n",
        "#### Challenge: Retrieving the restaurant review numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ5Nep3Xlc6U",
        "colab_type": "text"
      },
      "source": [
        "Can you repeat the above process for finding the review number for each restaurant?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfmFxK38lwbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ANSWER:\n",
        "# retriving restaurant review numbers\n",
        "\n",
        "for review in soup.find_all(\"span\",attrs={'class':'underline-hover'}):\n",
        "  s = review.text\n",
        "  print(s[s.find(\"(\")+1:s.find(\")\")])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}